# Configuração geral
WORKERS=4 # : Set to (2 x num_cores) + 1
TIMEOUT=120

# Seleção do provedor de IA
AI_PROVIDER=openai # openai, gemini, anthropic, deepseek, grok, llama_local

# Configurações da OpenAI
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Configurações do Gemini (Google)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-pro

# Configurações da Anthropic (Claude)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Configurações do DeepSeek
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-vl

# Configurações do Grok (xAI)
GROK_API_KEY=your_grok_api_key_here
GROK_MODEL=grok-2

# Configurações para o Llama rodando localmente
LLAMA_MODEL_PATH=/app/models/llama-3-8b.gguf
LLAMA_N_CTX=4096
LLAMA_N_GPU_LAYERS=-1 # -1 para usar todas as camadas disponíveis na GPU
LLAMA_SEED=42
